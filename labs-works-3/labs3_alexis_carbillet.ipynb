{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 3 ALEXIS CARBILLET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librairies\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "London = pd.read_csv('LondonTrain.csv') \n",
    "NY = pd.read_csv('NYTrain.csv')\n",
    "Singapore = pd.read_csv('SingaporeTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('London shape: ', London.shape)        # (3278, 10)\n",
    "print('London columns: ',London.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NY shape: ', NY.shape)                # (2261, 10)\n",
    "print('NY columns: ',NY.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Singapore shape: ', Singapore.shape)  # (4702, 10)\n",
    "print('Singapore columns: ',Singapore.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The three datasets have the same columns so they can be merged without columns problem (lack of features...)\n",
    "\n",
    "Columns: ['row ID', 'educationInfoForAgeGroupEstimation','workInfoForAgeGroupEstimation', 'gender', 'realAge', 'ageGroup', 'relationship', 'educationLevel', 'occupation', 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess data     \n",
    "def convert_id(data): # convert hex in int\n",
    "    for i in range(len(data)):\n",
    "        data.iloc[i]= int(data.iloc[i], 16)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):  # problem, everything become -1\n",
    "    x=data.unique()\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(x)):\n",
    "            if data[i]==x[j]:\n",
    "                data[i]=j\n",
    "        if data[i]!=data[i]:\n",
    "            data[i]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    dataset['row ID']=convert_id(dataset['row ID'])\n",
    "    convert(dataset['gender'])\n",
    "    convert(dataset['relationship'])\n",
    "    convert(dataset['ageGroup'])\n",
    "    convert(dataset['income'])\n",
    "    convert(dataset['educationLevel'])\n",
    "    convert(dataset['occupation'])\n",
    "    convert(dataset['realAge'])\n",
    "    convert(dataset['educationInfoForAgeGroupEstimation'])\n",
    "    convert(dataset['workInfoForAgeGroupEstimation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## London preprocess\n",
    "preprocess(London)\n",
    "London.to_csv('London_modified.csv') # avoid to preprocess again the whole data for each test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NY preprocess\n",
    "preprocess(NY)\n",
    "NY.to_csv('NY_modified.csv') # avoid to preprocess again the whole data for each test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Singapore preprocess\n",
    "preprocess(Singapore)\n",
    "Singapore.to_csv('Singapore_modified.csv') # avoid to preprocess again the whole data for each test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(nb,train,test,y,yt,height,height_f1,type,subject, models):\n",
    "    nb.fit(train, y)\n",
    "    models.append(nb)\n",
    "    w=nb.score(test, yt)\n",
    "    z=f1_score(yt, nb.predict(test),average='weighted')\n",
    "    # k = cross_val_score(nb, train, y, cv=10)\n",
    "    print(subject,': the mean accuracy obtained with ',type,' is:',w)\n",
    "    print(subject,': the f1 score obtained with ',type,' is:',z)\n",
    "    # print(subject,': the f1 score obtained with svd and ',type,' is:',k)\n",
    "    height.append(w)\n",
    "    height_f1.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml(train,test,y,yt,subject):\n",
    "    height=[]\n",
    "    height_f1=[]\n",
    "    models=[]\n",
    "    bars=['perceptron','MLP','tree','logistic regression','kNN 3 neighbors','kNN 7 neighbors','kNN 15 neighbors','SVC','Random Forest', 'Extra Trees', 'Bagging', 'Gaussian', 'Gradient Boosting', 'LDA']\n",
    "    # perceptron\n",
    "    nb = Perceptron(tol=1e-3, random_state=0)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'perceptron',subject, models)\n",
    "    # multi-layer perceptron\n",
    "    nb = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'multi-layer perceptron',subject, models)\n",
    "    # tree classifier\n",
    "    nb = DecisionTreeClassifier(random_state=0)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'tree',subject, models)\n",
    "    # logistic regression\n",
    "    nb = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'logistic regression',subject, models)\n",
    "    # kNN 3\n",
    "    nb = KNeighborsClassifier(n_neighbors=3)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'kNN 3 neighbors',subject, models)\n",
    "    # kNN 7\n",
    "    nb = KNeighborsClassifier(n_neighbors=7)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'kNN 7 neighbors',subject, models)\n",
    "    # kNN 15\n",
    "    nb = KNeighborsClassifier(n_neighbors=15)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'kNN 15 neighbors',subject, models)\n",
    "    # SVC\n",
    "    nb = SVC(gamma='auto')\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'SVC',subject, models)\n",
    "    # random forest\n",
    "    nb = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'random forest',subject, models)\n",
    "    # extra trees\n",
    "    nb = ExtraTreesClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'extra trees',subject, models)\n",
    "    # bagging\n",
    "    nb = BaggingClassifier(n_estimators=100, random_state=0)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'bagging',subject, models)\n",
    "    # GaussianNB\n",
    "    nb = GaussianNB()\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'gaussian',subject, models)\n",
    "    # GradientBoosting\n",
    "    nb = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "    fit(nb,train,test,y,yt,height,height_f1,' Gradient Boosting',subject, models)\n",
    "    # LinearDiscriminantAnalysis\n",
    "    nb = LinearDiscriminantAnalysis()\n",
    "    fit(nb,train,test,y,yt,height,height_f1,'LinearDiscriminantAnalysis',subject, models)\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.figure()\n",
    "\n",
    "    title2='F1 score for '+subject+' prediction'\n",
    "    plt.title(title2)\n",
    "    plt.bar(y_pos, height_f1)  # Create bars\n",
    "    plt.xticks(y_pos, bars, rotation=90) # Create names on the x-axis\n",
    "    plt.subplots_adjust(bottom=0.3, top=0.95) # Custom the subplot layout\n",
    "    plt.show()    # Show graphic\n",
    "    print('the best one for ', subject,' is ',bars[height_f1.index(max(height_f1))],' with a F1 score of ',height_f1[height_f1.index(max(height_f1))])\n",
    "    return models[height_f1.index(max(height_f1))]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I decided to predict the genre, but any column can be chosen as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## study for London dataset\n",
    "London = pd.read_csv('London_modified.csv') \n",
    "labels_london = London['gender']\n",
    "London = London.drop(['gender'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(London, labels_london, test_size=0.30, random_state=42)\n",
    "ml(X_train, X_test, y_train, y_test, 'London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## study for NY dataset\n",
    "NY = pd.read_csv('NY_modified.csv') \n",
    "labels_NY = NY['gender']\n",
    "NY = NY.drop(['gender'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(NY, labels_NY, test_size=0.30, random_state=42)\n",
    "ml(X_train, X_test, y_train, y_test, 'NY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## study for Singapore dataset\n",
    "Singapore = pd.read_csv('Singapore_modified.csv') \n",
    "labels_singapore = Singapore['gender']\n",
    "Singapore = Singapore.drop(['gender'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Singapore, labels_singapore, test_size=0.30, random_state=42)\n",
    "ml(X_train, X_test, y_train, y_test, 'Singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## whole study\n",
    "def whole(x1,y1,x2,y2,x3,y3):\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.30, random_state=42)\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.30, random_state=42)\n",
    "    X_train3, X_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.30, random_state=42)\n",
    "\n",
    "    nb = ml(X_train1, X_test1, y_train1, y_test1, 'London')\n",
    "    print(nb)\n",
    "    p=nb.predict(X_test1)\n",
    "    nb2 = ml(X_train2, X_test2, y_train2, y_test2, 'NY')\n",
    "    print(nb2)\n",
    "    p2=nb2.predict(X_test2)\n",
    "    nb3 = ml(X_train3, X_test3, y_train3, y_test3, 'Singapore')\n",
    "    print(nb3)\n",
    "    p3=nb3.predict(X_test3)\n",
    "\n",
    "    X=np.concatenate((p,p2),axis=0)\n",
    "    X=np.concatenate((X,p3),axis=0)\n",
    "    X=X.reshape(-1, 1)\n",
    "    y=np.zeros(p.shape)\n",
    "    y2=np.ones(p2.shape)\n",
    "    y3=np.ones(p3.shape)*2\n",
    "    Y=np.concatenate((y,y2),axis=0)\n",
    "    Y=np.concatenate((Y,y3),axis=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
    "    ml(X_train, X_test, y_train, y_test, 'Fusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole(London, labels_london, NY, labels_NY, Singapore, labels_singapore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
